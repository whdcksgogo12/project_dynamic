{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import re\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "os.chdir(r'C:\\\\Users\\\\PC\\\\Desktop\\\\pricing_project\\\\data')\n",
    "os.listdir()\n",
    "\n",
    "custom = pd.read_csv(os.listdir()[0])\n",
    "master = pd.read_csv(os.listdir()[1])\n",
    "product = pd.read_csv(os.listdir()[2])\n",
    "search1 = pd.read_csv(os.listdir()[3])   \n",
    "search2 = pd.read_csv(os.listdir()[-2])\n",
    "session = pd.read_csv(os.listdir()[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% 1. Data preprocessing\n",
    "\n",
    "#%% (1) Dataset 'Product'\n",
    "\n",
    "# -> 3개의 키값에서 2개의 키값으로 agg\n",
    "\n",
    "# 구매가격 변수를 str -> int 변환.\n",
    "product['PD_BUY_AM'] = list(map(lambda x:x.replace(\",\",\"\"),product['PD_BUY_AM']))\n",
    "product['PD_BUY_AM'] = product['PD_BUY_AM'].astype(int)\n",
    "\n",
    "# 구매개수 변수를 str&int -> int로 변환.\n",
    "product['PD_BUY_CT'] = product['PD_BUY_CT'].astype(str)\n",
    "product['PD_BUY_CT'] = list(map(lambda x:x.replace(\",\",\"\"),product['PD_BUY_CT']))\n",
    "product['PD_BUY_CT'] = product['PD_BUY_CT'].astype(int)\n",
    "\n",
    "## product에 새로운 열 \"TOT_AM\" 생성 (PD_BUY_AM는 제품 하나 당 개수이므로, 이를 구매한 제품의 갯수와 곱한 \"총 지출 금액\"이 \"TOT_AM\"임)\n",
    "product[\"TOT_AM\"] = product[\"PD_BUY_AM\"] * product[\"PD_BUY_CT\"]\n",
    "\n",
    "# CLNT_ID와 SESS_ID가 모두 같은 행들을 \"TOT_AM\",\"PD_BUY_CT\",\"PD_BUY_AM\"에 대해 합계,평균,표준편차를 구한 것\n",
    "product_agg = product.groupby(['CLNT_ID', 'SESS_ID'])[['TOT_AM','PD_BUY_CT','PD_BUY_AM']].agg(['sum','mean'])\n",
    "product_agg.columns= list(map(lambda x:x[0]+'_'+x[1],list(product_agg)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%% (2) Dataset 'Session'\n",
    "\n",
    "# SESS_DT을 datetime 자료형으로 변환.\n",
    "session['SESS_DT'] = pd.to_datetime(session['SESS_DT'], format = '%Y%m%d')\n",
    "## 월,주,일 변수 생성. 19 -> 1월 1일 이후 19번째 주 double check  0 = 월요일, 6 = 일요일  double check\n",
    "session['MONTH'] = list(map(lambda x:x.month,session['SESS_DT'])) \n",
    "session['WEEK'] = list(map(lambda x:x.week,session['SESS_DT'])) \n",
    "session['DAY'] = list(map(lambda x:x.weekday(),session['SESS_DT'])) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% (3) Dataset 'search1','search2'\n",
    "\n",
    "# 서로 다른 key구조를 모델에 적용가능한 형태로 통일.\n",
    "\n",
    "# merge를 위해 SESS_DT 형식 동일하게 변경. \n",
    "search2['SESS_DT'] = pd.to_datetime(search2['SESS_DT'], format = '%Y%m%d')\n",
    "\n",
    "# 검색량 변수를 str&int -> int로 변환 후 이름 변경.\n",
    "search2['SEARCH_CNT'] = search2['SEARCH_CNT'].astype(str)\n",
    "search2['SEARCH_CNT'] = list(map(lambda x:x.replace(\",\",\"\"), search2['SEARCH_CNT']))\n",
    "search2['SEARCH_CNT'] =  search2['SEARCH_CNT'].astype(int)\n",
    "search2.rename(columns={'SEARCH_CNT': 'SEARCH_TOT'}, inplace=True) # Search1과 컬럼명이 동일하지만 의미가 다르므로 이름 변경.\n",
    "\n",
    "# 전체검색량, 검색 키워드 갯수, 개인검색량, 전체검색량 대비 개인 검색량, 변수 생성.\n",
    "search = pd.merge(search1,session.loc[:,['CLNT_ID','SESS_ID','SESS_DT']],how = 'left', on = ['CLNT_ID','SESS_ID']) \n",
    "search = pd.merge(search,search2.loc[:,['SESS_DT','KWD_NM','SEARCH_TOT']],how = 'left', on = ['KWD_NM','SESS_DT']) \n",
    "cnt = search.groupby(['CLNT_ID','SESS_ID']).count()['KWD_NM'] # 순서 유의.\n",
    "search = search.groupby(['CLNT_ID','SESS_ID']).sum() # 이 부분에서 고유한 키값으로 줄어듬. \n",
    "search['KWD_CNT'] = cnt\n",
    "search['SEARCH_RATIO'] = search.SEARCH_CNT / search.SEARCH_TOT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% (4) Make y \n",
    "\n",
    "## y labeling\n",
    "# 날짜 차이 구하기\n",
    "session = session.sort_values(['CLNT_ID','SESS_DT']) # diff를 사용하기 위해 날짜순으로 정렬\n",
    "session['DT_DIFF'] = session['SESS_DT'].diff() # (1) 일단은 전체에 대해 차이를 구해준 다음\n",
    "session.loc[session.CLNT_ID != session.CLNT_ID.shift(),'DT_DIFF'] = None #(2) CLNT_ID가 변하는 경우에만 None로 수정\n",
    "# 새롭게 라벨 제작\n",
    "Y = session['DT_DIFF'].dt.days.tolist() # date 형태를 int 형태로 변형\n",
    "a = list()\n",
    "a.append(np.nan)\n",
    "Y = Y[1:]+a # 한칸씩 올리고 마지막에 np.nan 추가 \n",
    "session['y']=Y #라벨 추가\n",
    "session = session[pd.notnull(session['y'])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% (5) Product Vector mapping\n",
    "\n",
    "# #### SESS_ID마다 구매한 상품 쌓아 - 그 대분류 쌓아 - 대분류 구매 패턴 (빈도 / 여부)\n",
    "# #### 변수 1 : 세션 내 쇼핑 Category 구매 빈도(단순 횟수)\n",
    "# #### 변수 2 : 세션 내 쇼핑 Category 구매 여부(0,1 binary vec)\n",
    "\n",
    "product = product.sort_values(by=['CLNT_ID', 'SESS_ID'], axis=0, ascending=[True, False])\n",
    "master= master.sort_values(by='PD_C',ascending=True)\n",
    "product_dummy =product.merge(master,on='PD_C',how='left')\n",
    "\n",
    "#사전식으로 대분류 배열 정렬 (ㄱ으로 시작하여 ㅎ으로 끝나도록)\n",
    "clac1_list=list(product_dummy['CLAC1_NM'].unique())\n",
    "clac1_list.sort()\n",
    "CLAC1_NM_dict=dict(zip(clac1_list,range(0,37)))\n",
    "\n",
    "#대분류 한글 -> 배정된 숫자로 변경\n",
    "product_dummy=product_dummy.replace({\"CLAC1_NM\": CLAC1_NM_dict})\n",
    "#대분류 더미변수화\n",
    "product_dummy = pd.concat([product_dummy, pd.get_dummies(product_dummy['CLAC1_NM'])], axis=1)\n",
    "#세션별 대분류 더미변수 갯수 \n",
    "product_dummy_agg= product_dummy.groupby(['CLNT_ID', 'SESS_ID'])[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36].agg(['sum'])\n",
    "#groupby -> dataframe \n",
    "product_dummy_agg=pd.DataFrame(product_dummy_agg)\n",
    "product_dummy_agg = product_dummy_agg.reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% (6) Merge datasets\n",
    "\n",
    "raw = pd.merge(session,custom, how = 'left', on = ['CLNT_ID']) \n",
    "raw = pd.merge(raw,product_agg, how = 'left', on = ['CLNT_ID','SESS_ID']) \n",
    "raw = pd.merge(raw,search,how = 'left', on = ['CLNT_ID','SESS_ID']) \n",
    "raw = pd.merge(raw,product_dummy_agg, how = 'left', on = ['CLNT_ID','SESS_ID']) \n",
    "raw = raw.reindex(columns=sorted(list(raw)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% (7) preprocessing of of raw data for deep learning\n",
    "\n",
    "# age selection\n",
    "\n",
    "raw['CLNT_AGE'].fillna(0, inplace=True) # 비회원 0\n",
    "raw = raw[raw['CLNT_AGE']<50] # 비회원 + 20 ~40 대 \n",
    "\n",
    "# dummy\n",
    "\n",
    "## CLNT_AGE : float to object\n",
    "raw['CLNT_AGE'] = raw['CLNT_AGE'].astype(object)\n",
    "\n",
    "## 도시명은 163개 Unique 값으로, dummy가 너무 많아져 삭제\n",
    "\n",
    "## 성별(CLNT_GENDER), 사용자 기기(DVC_CTG_NM), 행정구역(ZON_NM),나이대(CLNT_AGE) encoding\n",
    "raw=pd.concat([raw, pd.get_dummies(raw[['CLNT_GENDER','ZON_NM','DVC_CTG_NM','CLNT_AGE']])], axis =1 )\n",
    "\n",
    "# Deletion  ; 기존 string 변수, 모델링에 쓰지 않을 변수 삭제\n",
    "del(raw2['DT_DIFF'])\n",
    "del(raw2['CLNT_AGE'])\n",
    "del(raw2['SESS_DT'])\n",
    "del(raw2['CITY_NM'])\n",
    "del(raw2['CLNT_GENDER'])\n",
    "del(raw2['DVC_CTG_NM'])\n",
    "del(raw2['ZON_NM'])\n",
    "del(raw2['CLNT_ID'])\n",
    "del(raw2['SESS_ID'])\n",
    "\n",
    "# column order setting\n",
    "cols = raw.columns.tolist()\n",
    "cols = cols[:16] + cols[17:-1] + [cols[16]]\n",
    "raw = raw[cols]\n",
    "\n",
    "# data type change\n",
    "for i in cols : \n",
    "    raw[i] = pd.to_numeric(raw[i], errors='coerce').fillna(0, downcast='infer')\n",
    "raw = raw[cols].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DAY                         float64\n",
       "KWD_CNT                     float64\n",
       "MONTH                       float64\n",
       "PD_BUY_AM_mean              float64\n",
       "PD_BUY_AM_sum               float64\n",
       "PD_BUY_CT_mean              float64\n",
       "PD_BUY_CT_sum               float64\n",
       "SEARCH_CNT                  float64\n",
       "SEARCH_RATIO                float64\n",
       "SEARCH_TOT                  float64\n",
       "SESS_SEQ                    float64\n",
       "TOT_AM_mean                 float64\n",
       "TOT_AM_sum                  float64\n",
       "TOT_PAG_VIEW_CT             float64\n",
       "TOT_SESS_HR_V               float64\n",
       "WEEK                        float64\n",
       "(0, sum)                    float64\n",
       "(1, sum)                    float64\n",
       "(2, sum)                    float64\n",
       "(3, sum)                    float64\n",
       "(4, sum)                    float64\n",
       "(5, sum)                    float64\n",
       "(6, sum)                    float64\n",
       "(7, sum)                    float64\n",
       "(8, sum)                    float64\n",
       "(9, sum)                    float64\n",
       "(10, sum)                   float64\n",
       "(11, sum)                   float64\n",
       "(12, sum)                   float64\n",
       "(13, sum)                   float64\n",
       "                             ...   \n",
       "(33, sum)                   float64\n",
       "(34, sum)                   float64\n",
       "(35, sum)                   float64\n",
       "(36, sum)                   float64\n",
       "CLNT_GENDER_F               float64\n",
       "CLNT_GENDER_M               float64\n",
       "ZON_NM_Busan                float64\n",
       "ZON_NM_Chungcheongbuk-do    float64\n",
       "ZON_NM_Chungcheongnam-do    float64\n",
       "ZON_NM_Daegu                float64\n",
       "ZON_NM_Daejeon              float64\n",
       "ZON_NM_Gangwon-do           float64\n",
       "ZON_NM_Gwangju              float64\n",
       "ZON_NM_Gyeonggi-do          float64\n",
       "ZON_NM_Gyeongsangbuk-do     float64\n",
       "ZON_NM_Gyeongsangnam-do     float64\n",
       "ZON_NM_Incheon              float64\n",
       "ZON_NM_Jeju-do              float64\n",
       "ZON_NM_Jeollabuk-do         float64\n",
       "ZON_NM_Jeollanam-do         float64\n",
       "ZON_NM_Seoul                float64\n",
       "ZON_NM_Ulsan                float64\n",
       "DVC_CTG_NM_desktop          float64\n",
       "DVC_CTG_NM_mobile           float64\n",
       "DVC_CTG_NM_tablet           float64\n",
       "CLNT_AGE_0.0                float64\n",
       "CLNT_AGE_10.0               float64\n",
       "CLNT_AGE_20.0               float64\n",
       "CLNT_AGE_30.0               float64\n",
       "y                           float64\n",
       "Length: 79, dtype: object"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('raw.pickle','wb')as handle:\n",
    "    pickle.dump(raw,handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supplimentary EDA\n",
    "\n",
    "\n",
    "#날짜 차이를 기준으로 그룹형성 -> 갯수(size) 구하기 -> index제거\n",
    "test=raw.groupby('DT_DIFF',as_index=False).size().reset_index(name = 'count')\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "plt.plot(test['DT_DIFF'],test['count'])\n",
    "\n",
    "\n",
    "def findSplitPoint(test, n) : \n",
    "   \n",
    "    left = list()\n",
    "    right = list()\n",
    "    splitpoint = list()\n",
    "    \n",
    "    leftSum = 0 \n",
    "    # traverse array element \n",
    "    for i in range(0, n) : \n",
    "       \n",
    "        # add current element to left Sum \n",
    "        leftSum += test.iloc[i,1]  \n",
    "        left.append(leftSum)\n",
    "        splitpoint.append(i+1)\n",
    "        # find sum of rest array elements (rightSum) \n",
    "        rightSum = 0 \n",
    "        for j in range(i+1, n) : \n",
    "            rightSum += test.iloc[j,1]\n",
    "        \n",
    "        right.append(rightSum)\n",
    "    # split poindex \n",
    "    return left,right,splitpoint\n",
    "\n",
    "\n",
    "left,right,splitpoint = findSplitPoint(test,180)\n",
    "\n",
    "Decider =pd.DataFrame(np.vstack([splitpoint,left, right]).T,\n",
    "              columns=['splitpoint','leftsum', 'rightsum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
